{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EliteBook\\Anaconda3\\envs\\env1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py:1750: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "from keras import layers, models, optimizers\n",
    "from keras.layers import Input, Conv2D, Dense\n",
    "from keras.layers import Reshape, Layer, Lambda\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from keras import initializers\n",
    "from keras.optimizers import Adam\n",
    "from keras.datasets import mnist\n",
    "from keras import backend as K\n",
    "from keras.datasets import cifar10\n",
    "import matplotlib as plt\n",
    "from skimage.color import rgb2gray\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2gray\n",
    "from skimage import data\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()\n",
    "writer = tf.summary.FileWriter(\"c:\\logs\", sess.graph)\n",
    "\n",
    "\n",
    "def squash(output_vector, axis=-1):\n",
    "    norm = tf.reduce_sum(tf.square(output_vector), axis, keep_dims=True)\n",
    "    return output_vector * norm / ((1 + norm) * tf.sqrt(norm + 1.0e-10))\n",
    "\n",
    "class MaskingLayer(Layer):\n",
    "    def call(self, inputs, **kwargs):\n",
    "        input, mask = inputs\n",
    "        return K.batch_dot(input, mask, 1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        *_, output_shape = input_shape[0]\n",
    "        return (None, output_shape)\n",
    "def PrimaryCapsule(n_vector, n_channel, n_kernel_size, n_stride, padding='valid'):\n",
    "    def builder(inputs):\n",
    "        output = Conv2D(filters=n_vector * n_channel, kernel_size=n_kernel_size, strides=n_stride, padding=padding)(inputs)\n",
    "        output = Reshape( target_shape=[-1, n_vector], name='primary_capsule_reshape')(output)\n",
    "        return Lambda(squash, name='primary_capsule_squash')(output)\n",
    "    return builder\n",
    "class CapsuleLayer(Layer):\n",
    "    def __init__(self, n_capsule, n_vec, n_routing, **kwargs):\n",
    "        super(CapsuleLayer, self).__init__(**kwargs)\n",
    "        self.n_capsule = n_capsule\n",
    "        self.n_vector = n_vec\n",
    "        self.n_routing = n_routing\n",
    "        self.kernel_initializer = initializers.get('he_normal')\n",
    "        self.bias_initializer = initializers.get('zeros')\n",
    "\n",
    "    def build(self, input_shape): # input_shape is a 4D tensor\n",
    "        _, self.input_n_capsule, self.input_n_vector, *_ = input_shape\n",
    "        self.W = self.add_weight(shape=[self.input_n_capsule, self.n_capsule, self.input_n_vector, self.n_vector], initializer=self.kernel_initializer, name='W')\n",
    "        self.bias = self.add_weight(shape=[1, self.input_n_capsule, self.n_capsule, 1, 1], initializer=self.bias_initializer, name='bias', trainable=False)\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        input_expand = tf.expand_dims(tf.expand_dims(inputs, 2), 2)\n",
    "        input_tiled = tf.tile(input_expand, [1, 1, self.n_capsule, 1, 1])\n",
    "        input_hat = tf.scan(lambda ac, x: K.batch_dot(x, self.W, [3, 2]), elems=input_tiled, initializer=K.zeros( [self.input_n_capsule, self.n_capsule, 1, self.n_vector]))\n",
    "        for i in range(self.n_routing): # routing\n",
    "            c = tf.nn.softmax(self.bias, dim=2)\n",
    "            outputs = squash(tf.reduce_sum( c * input_hat, axis=1, keep_dims=True))\n",
    "            if i != self.n_routing - 1:\n",
    "                self.bias += tf.reduce_sum(input_hat * outputs, axis=-1, keep_dims=True)\n",
    "        return tf.reshape(outputs, [-1, self.n_capsule, self.n_vector])\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        # output current layer capsules\n",
    "        return (None, self.n_capsule, self.n_vector)\n",
    "class LengthLayer(Layer):\n",
    "    def call(self, inputs, **kwargs):\n",
    "        return tf.sqrt(tf.reduce_sum(tf.square(inputs), axis=-1, keep_dims=False))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        *output_shape, _ = input_shape\n",
    "        return tuple(output_shape)\n",
    "def margin_loss(y_ground_truth, y_prediction):\n",
    "    _m_plus = 0.9\n",
    "    _m_minus = 0.1\n",
    "    _lambda = 0.5\n",
    "    L = y_ground_truth * tf.square(tf.maximum(0., _m_plus - y_prediction)) + _lambda * ( 1 - y_ground_truth) * tf.square(tf.maximum(0., y_prediction - _m_minus))\n",
    "    return tf.reduce_mean(tf.reduce_sum(L, axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "\n",
    "x_train = x_train.reshape(-1, 32, 32, 3).astype('float32') / 255.0\n",
    "x_test = x_test.reshape(-1, 32, 32, 3).astype('float32') / 255.0\n",
    "y_train = to_categorical(y_train.astype('float32'))\n",
    "y_test = to_categorical(y_test.astype('float32'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversion to grayscale will follow using the function rgb2gray()\n",
    "The weights used in this conversion are calibrated for contemporary CRT phosphors:\n",
    "\n",
    "Y = 0.2125 R + 0.7154 G + 0.0721 B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting them to graysclae\n",
    "x_train = rgb2gray(x_train)\n",
    "x_test = rgb2gray(x_test)\n",
    "y_train = rgb2gray(y_train)\n",
    "y_test = rgb2gray(y_test)\n",
    "\n",
    "#Now concatenating the data\n",
    "X = np.concatenate((x_train, x_test), axis=0)\n",
    "Y = np.concatenate((y_train, y_test), axis=0)\n",
    "#Reshaping X to make it have same shape as expected by the network\n",
    "X = X.reshape(-1,32,32,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable += will be deprecated. Use variable.assign_add if you want assignment to the variable value or 'x = x + y' if you want a new python Tensor object.\n"
     ]
    }
   ],
   "source": [
    "input_shape = [32, 32,1]\n",
    "n_class = 10\n",
    "n_routing = 3\n",
    "\n",
    "x = Input(shape=input_shape)\n",
    "conv1 = Conv2D(filters=256, kernel_size=9, strides=1, padding='valid', activation='relu', name='conv1')(x)\n",
    "primary_capsule = PrimaryCapsule( n_vector=8, n_channel=32, n_kernel_size=9, n_stride=2)(conv1)\n",
    "digit_capsule = CapsuleLayer( n_capsule=n_class, n_vec=16, n_routing=n_routing, name='digit_capsule')(primary_capsule)\n",
    "output_capsule = LengthLayer(name='output_capsule')(digit_capsule)\n",
    "\n",
    "mask_input = Input(shape=(n_class, ))\n",
    "mask = MaskingLayer()([digit_capsule, mask_input])  # two inputs\n",
    "dec = Dense(512, activation='relu')(mask)\n",
    "dec = Dense(1024, activation='relu')(dec)\n",
    "dec = Dense(1024, activation='sigmoid')(dec) #32x32 = 1024 pixels per image\n",
    "dec = Reshape(input_shape)(dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/3\n",
      "48000/48000 [==============================] - 7034s 147ms/step - loss: 0.6527 - output_capsule_loss: 0.4920 - reshape_16_loss: 0.1607 - output_capsule_margin_loss: 0.4920 - output_capsule_mean_absolute_error: 0.2741 - output_capsule_acc: 0.2480 - reshape_16_margin_loss: 3.7282 - reshape_16_mean_absolute_error: 0.1607 - reshape_16_acc: 9.8501e-04 - val_loss: 0.5633 - val_output_capsule_loss: 0.4276 - val_reshape_16_loss: 0.1357 - val_output_capsule_margin_loss: 0.4276 - val_output_capsule_mean_absolute_error: 0.2619 - val_output_capsule_acc: 0.3643 - val_reshape_16_margin_loss: 3.6770 - val_reshape_16_mean_absolute_error: 0.1357 - val_reshape_16_acc: 0.0013\n",
      "Epoch 2/3\n",
      "48000/48000 [==============================] - 6884s 143ms/step - loss: 0.5528 - output_capsule_loss: 0.4203 - reshape_16_loss: 0.1325 - output_capsule_margin_loss: 0.4203 - output_capsule_mean_absolute_error: 0.2547 - output_capsule_acc: 0.3810 - reshape_16_margin_loss: 3.5604 - reshape_16_mean_absolute_error: 0.1325 - reshape_16_acc: 0.0011 - val_loss: 0.5330 - val_output_capsule_loss: 0.4076 - val_reshape_16_loss: 0.1255 - val_output_capsule_margin_loss: 0.4076 - val_output_capsule_mean_absolute_error: 0.2542 - val_output_capsule_acc: 0.4044 - val_reshape_16_margin_loss: 3.5599 - val_reshape_16_mean_absolute_error: 0.1255 - val_reshape_16_acc: 0.0013\n",
      "Epoch 3/3\n",
      "48000/48000 [==============================] - 6887s 143ms/step - loss: 0.5220 - output_capsule_loss: 0.3989 - reshape_16_loss: 0.1231 - output_capsule_margin_loss: 0.3989 - output_capsule_mean_absolute_error: 0.2493 - output_capsule_acc: 0.4189 - reshape_16_margin_loss: 3.5006 - reshape_16_mean_absolute_error: 0.1231 - reshape_16_acc: 0.0011 - val_loss: 0.5129 - val_output_capsule_loss: 0.3925 - val_reshape_16_loss: 0.1204 - val_output_capsule_margin_loss: 0.3925 - val_output_capsule_mean_absolute_error: 0.2483 - val_output_capsule_acc: 0.4216 - val_reshape_16_margin_loss: 3.3372 - val_reshape_16_mean_absolute_error: 0.1204 - val_reshape_16_acc: 0.0013\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a5355e3dc8>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = Model([x, mask_input], [output_capsule, dec])\n",
    "model.compile(optimizer='adam', loss=[ margin_loss, 'mae' ], metrics=[ margin_loss, 'mae', 'accuracy'])\n",
    "\n",
    "model.fit([X, Y], [Y, X], batch_size=128, epochs=3, validation_split=0.2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_21 (InputLayer)           (None, 32, 32, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 24, 24, 256)  20992       input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 8, 8, 256)    5308672     conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "primary_capsule_reshape (Reshap (None, 2048, 8)      0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "primary_capsule_squash (Lambda) (None, 2048, 8)      0           primary_capsule_reshape[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "digit_capsule (CapsuleLayer)    (None, 10, 16)       2641920     primary_capsule_squash[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "input_22 (InputLayer)           (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking_layer_10 (MaskingLayer) (None, 16)           0           digit_capsule[0][0]              \n",
      "                                                                 input_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 512)          8704        masking_layer_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 1024)         525312      dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 1024)         1049600     dense_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "output_capsule (LengthLayer)    (None, 10)           0           digit_capsule[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_16 (Reshape)            (None, 32, 32, 1)    0           dense_30[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 9,555,200\n",
      "Trainable params: 9,534,720\n",
      "Non-trainable params: 20,480\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.save('CapsNet_Cifar10_routing3_grayscale.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
