{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s look at how we can implement3 it using Keras* with TensorFlow* backend. You start by importing all the required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, models, optimizers\n",
    "from keras.layers import Input, Conv2D, Dense\n",
    "from keras.layers import Reshape, Layer, Lambda\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from keras import initializers\n",
    "from keras.optimizers import Adam\n",
    "from keras.datasets import mnist\n",
    "from keras import backend as K\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let’s define the Squash function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squash(output_vector, axis=-1):\n",
    "    norm = tf.reduce_sum(tf.square(output_vector), axis, keep_dims=True)\n",
    "    return output_vector * norm / ((1 + norm) * tf.sqrt(norm + 1.0e-10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After defining the Squash function, we can define the masking layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskingLayer(Layer):\n",
    "    def call(self, inputs, **kwargs):\n",
    "        input, mask = inputs\n",
    "        return K.batch_dot(input, mask, 1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        *_, output_shape = input_shape[0]\n",
    "        return (None, output_shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let’s define the primary Capsule function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrimaryCapsule(n_vector, n_channel, n_kernel_size, n_stride, padding='valid'):\n",
    "    def builder(inputs):\n",
    "        output = Conv2D(filters=n_vector * n_channel, kernel_size=n_kernel_size, strides=n_stride, padding=padding)(inputs)\n",
    "        output = Reshape( target_shape=[-1, n_vector], name='primary_capsule_reshape')(output)\n",
    "        return Lambda(squash, name='primary_capsule_squash')(output)\n",
    "    return builder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, let’s write the capsule layer class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapsuleLayer(Layer):\n",
    "    def __init__(self, n_capsule, n_vec, n_routing, **kwargs):\n",
    "        super(CapsuleLayer, self).__init__(**kwargs)\n",
    "        self.n_capsule = n_capsule\n",
    "        self.n_vector = n_vec\n",
    "        self.n_routing = n_routing\n",
    "        self.kernel_initializer = initializers.get('he_normal')\n",
    "        self.bias_initializer = initializers.get('zeros')\n",
    "\n",
    "    def build(self, input_shape): # input_shape is a 4D tensor\n",
    "        _, self.input_n_capsule, self.input_n_vector, *_ = input_shape\n",
    "        self.W = self.add_weight(shape=[self.input_n_capsule, self.n_capsule, self.input_n_vector, self.n_vector], initializer=self.kernel_initializer, name='W')\n",
    "        self.bias = self.add_weight(shape=[1, self.input_n_capsule, self.n_capsule, 1, 1], initializer=self.bias_initializer, name='bias', trainable=False)\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        input_expand = tf.expand_dims(tf.expand_dims(inputs, 2), 2)\n",
    "        input_tiled = tf.tile(input_expand, [1, 1, self.n_capsule, 1, 1])\n",
    "        input_hat = tf.scan(lambda ac, x: K.batch_dot(x, self.W, [3, 2]), elems=input_tiled, initializer=K.zeros( [self.input_n_capsule, self.n_capsule, 1, self.n_vector]))\n",
    "        for i in range(self.n_routing): # routing\n",
    "            c = tf.nn.softmax(self.bias, dim=2)\n",
    "            outputs = squash(tf.reduce_sum( c * input_hat, axis=1, keep_dims=True))\n",
    "            if i != self.n_routing - 1:\n",
    "                self.bias += tf.reduce_sum(input_hat * outputs, axis=-1, keep_dims=True)\n",
    "        return tf.reshape(outputs, [-1, self.n_capsule, self.n_vector])\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        # output current layer capsules\n",
    "        return (None, self.n_capsule, self.n_vector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class below will compute the length of the capsule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LengthLayer(Layer):\n",
    "    def call(self, inputs, **kwargs):\n",
    "        return tf.sqrt(tf.reduce_sum(tf.square(inputs), axis=-1, keep_dims=False))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        *output_shape, _ = input_shape\n",
    "        return tuple(output_shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below will compute the margin loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def margin_loss(y_ground_truth, y_prediction):\n",
    "    _m_plus = 0.9\n",
    "    _m_minus = 0.1\n",
    "    _lambda = 0.5\n",
    "    L = y_ground_truth * tf.square(tf.maximum(0., _m_plus - y_prediction)) + _lambda * ( 1 - y_ground_truth) * tf.square(tf.maximum(0., y_prediction - _m_minus))\n",
    "    return tf.reduce_mean(tf.reduce_sum(L, axis=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After defining the different necessary building blocks of the network we can now preprocess the MNIST dataset input for the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 43s 4us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "y_train = to_categorical(y_train.astype('float32'))\n",
    "y_test = to_categorical(y_test.astype('float32'))\n",
    "X = np.concatenate((x_train, x_test), axis=0)\n",
    "Y = np.concatenate((y_train, y_test), axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are some variables that will represent the shape of the input, number of output classes, and number of routings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = [28, 28, 1]\n",
    "n_class = 10\n",
    "n_routing = 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let’s create the encoder part of the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Input(shape=input_shape)\n",
    "conv1 = Conv2D(filters=256, kernel_size=9, strides=1, padding='valid', activation='relu', name='conv1')(x)\n",
    "primary_capsule = PrimaryCapsule( n_vector=8, n_channel=32, n_kernel_size=9, n_stride=2)(conv1)\n",
    "digit_capsule = CapsuleLayer( n_capsule=n_class, n_vec=16, n_routing=n_routing, name='digit_capsule')(primary_capsule)\n",
    "output_capsule = LengthLayer(name='output_capsule')(digit_capsule)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let’s create the decoder part of the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_input = Input(shape=(n_class, ))\n",
    "mask = MaskingLayer()([digit_capsule, mask_input])  # two inputs\n",
    "dec = Dense(512, activation='relu')(mask)\n",
    "dec = Dense(1024, activation='relu')(dec)\n",
    "dec = Dense(784, activation='sigmoid')(dec)\n",
    "dec = Reshape(input_shape)(dec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s create the entire model and compile it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([x, mask_input], [output_capsule, dec])\n",
    "model.compile(optimizer='adam', loss=[ margin_loss, 'mae' ], metrics=[ margin_loss, 'mae', 'accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view the layers and overall architecture of the entire model, we can use this command: model.summary()\n",
    "\n",
    "Finally, we can train the model for three epochs and find out how it will perform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\EliteBook\\Anaconda3\\envs\\env1\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\EliteBook\\Anaconda3\\envs\\env1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\EliteBook\\Anaconda3\\envs\\env1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\EliteBook\\Anaconda3\\envs\\env1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 56000 samples, validate on 14000 samples\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:From C:\\Users\\EliteBook\\Anaconda3\\envs\\env1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\EliteBook\\Anaconda3\\envs\\env1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\EliteBook\\Anaconda3\\envs\\env1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\EliteBook\\Anaconda3\\envs\\env1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\EliteBook\\Anaconda3\\envs\\env1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "56000/56000 [==============================] - 2856s 51ms/step - loss: 0.2062 - output_capsule_loss: 0.0785 - reshape_1_loss: 0.1276 - output_capsule_margin_loss: 0.0785 - output_capsule_mean_absolute_error: 0.0976 - output_capsule_acc: 0.9257 - reshape_1_margin_loss: 2.0951 - reshape_1_mean_absolute_error: 0.1276 - reshape_1_acc: 0.8018 - val_loss: 0.1215 - val_output_capsule_loss: 0.0199 - val_reshape_1_loss: 0.1016 - val_output_capsule_margin_loss: 0.0199 - val_output_capsule_mean_absolute_error: 0.0665 - val_output_capsule_acc: 0.9865 - val_reshape_1_margin_loss: 1.9490 - val_reshape_1_mean_absolute_error: 0.1016 - val_reshape_1_acc: 0.8034\n",
      "Epoch 2/3\n",
      "56000/56000 [==============================] - 2881s 51ms/step - loss: 0.1120 - output_capsule_loss: 0.0178 - reshape_1_loss: 0.0942 - output_capsule_margin_loss: 0.0178 - output_capsule_mean_absolute_error: 0.0675 - output_capsule_acc: 0.9877 - reshape_1_margin_loss: 1.7763 - reshape_1_mean_absolute_error: 0.0942 - reshape_1_acc: 0.8047 - val_loss: 0.0971 - val_output_capsule_loss: 0.0136 - val_reshape_1_loss: 0.0835 - val_output_capsule_margin_loss: 0.0136 - val_output_capsule_mean_absolute_error: 0.0620 - val_output_capsule_acc: 0.9902 - val_reshape_1_margin_loss: 1.4899 - val_reshape_1_mean_absolute_error: 0.0835 - val_reshape_1_acc: 0.8049\n",
      "Epoch 3/3\n",
      "56000/56000 [==============================] - 2663s 48ms/step - loss: 0.0901 - output_capsule_loss: 0.0127 - reshape_1_loss: 0.0774 - output_capsule_margin_loss: 0.0127 - output_capsule_mean_absolute_error: 0.0650 - output_capsule_acc: 0.9916 - reshape_1_margin_loss: 1.3484 - reshape_1_mean_absolute_error: 0.0774 - reshape_1_acc: 0.8058 - val_loss: 0.0897 - val_output_capsule_loss: 0.0182 - val_reshape_1_loss: 0.0714 - val_output_capsule_margin_loss: 0.0182 - val_output_capsule_mean_absolute_error: 0.0775 - val_output_capsule_acc: 0.9904 - val_reshape_1_margin_loss: 1.2030 - val_reshape_1_mean_absolute_error: 0.0714 - val_reshape_1_acc: 0.8056\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15dba2d0f08>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X, Y], [Y, X], batch_size=128, epochs=3, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('CapsNet_on_MNIST_weights.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 20, 20, 256)  20992       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 6, 6, 256)    5308672     conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "primary_capsule_reshape (Reshap (None, 1152, 8)      0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "primary_capsule_squash (Lambda) (None, 1152, 8)      0           primary_capsule_reshape[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "digit_capsule (CapsuleLayer)    (None, 10, 16)       1486080     primary_capsule_squash[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking_layer_1 (MaskingLayer)  (None, 16)           0           digit_capsule[0][0]              \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          8704        masking_layer_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1024)         525312      dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 784)          803600      dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output_capsule (LengthLayer)    (None, 10)           0           digit_capsule[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 28, 28, 1)    0           dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 8,153,360\n",
      "Trainable params: 8,141,840\n",
      "Non-trainable params: 11,520\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
