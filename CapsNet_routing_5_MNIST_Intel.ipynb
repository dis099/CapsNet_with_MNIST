{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\EliteBook\\Anaconda3\\envs\\env1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\EliteBook\\Anaconda3\\envs\\env1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\EliteBook\\Anaconda3\\envs\\env1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-1-ea74b9cdbc95>:15: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\EliteBook\\Anaconda3\\envs\\env1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-1-ea74b9cdbc95>:52: calling softmax (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n",
      "WARNING:tensorflow:Variable += will be deprecated. Use variable.assign_add if you want assignment to the variable value or 'x = x + y' if you want a new python Tensor object.\n",
      "WARNING:tensorflow:From C:\\Users\\EliteBook\\Anaconda3\\envs\\env1\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\EliteBook\\Anaconda3\\envs\\env1\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\EliteBook\\Anaconda3\\envs\\env1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\EliteBook\\Anaconda3\\envs\\env1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\EliteBook\\Anaconda3\\envs\\env1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 56000 samples, validate on 14000 samples\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:From C:\\Users\\EliteBook\\Anaconda3\\envs\\env1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\EliteBook\\Anaconda3\\envs\\env1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\EliteBook\\Anaconda3\\envs\\env1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\EliteBook\\Anaconda3\\envs\\env1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\EliteBook\\Anaconda3\\envs\\env1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "56000/56000 [==============================] - 5971s 107ms/step - loss: 0.2056 - output_capsule_loss: 0.0772 - reshape_1_loss: 0.1283 - output_capsule_margin_loss: 0.0772 - output_capsule_mean_absolute_error: 0.0931 - output_capsule_acc: 0.9256 - reshape_1_margin_loss: 2.0988 - reshape_1_mean_absolute_error: 0.1283 - reshape_1_acc: 0.8008 - val_loss: 0.1208 - val_output_capsule_loss: 0.0177 - val_reshape_1_loss: 0.1031 - val_output_capsule_margin_loss: 0.0177 - val_output_capsule_mean_absolute_error: 0.0605 - val_output_capsule_acc: 0.9874 - val_reshape_1_margin_loss: 1.9665 - val_reshape_1_mean_absolute_error: 0.1031 - val_reshape_1_acc: 0.8018\n",
      "Epoch 2/3\n",
      "56000/56000 [==============================] - 6065s 108ms/step - loss: 0.1137 - output_capsule_loss: 0.0169 - reshape_1_loss: 0.0968 - output_capsule_margin_loss: 0.0169 - output_capsule_mean_absolute_error: 0.0631 - output_capsule_acc: 0.9871 - reshape_1_margin_loss: 1.8064 - reshape_1_mean_absolute_error: 0.0968 - reshape_1_acc: 0.8027 - val_loss: 0.1017 - val_output_capsule_loss: 0.0130 - val_reshape_1_loss: 0.0886 - val_output_capsule_margin_loss: 0.0130 - val_output_capsule_mean_absolute_error: 0.0591 - val_output_capsule_acc: 0.9887 - val_reshape_1_margin_loss: 1.6056 - val_reshape_1_mean_absolute_error: 0.0886 - val_reshape_1_acc: 0.8040\n",
      "Epoch 3/3\n",
      "56000/56000 [==============================] - 6279s 112ms/step - loss: 0.0935 - output_capsule_loss: 0.0120 - reshape_1_loss: 0.0815 - output_capsule_margin_loss: 0.0120 - output_capsule_mean_absolute_error: 0.0601 - output_capsule_acc: 0.9910 - reshape_1_margin_loss: 1.4153 - reshape_1_mean_absolute_error: 0.0815 - reshape_1_acc: 0.8044 - val_loss: 0.0886 - val_output_capsule_loss: 0.0137 - val_reshape_1_loss: 0.0749 - val_output_capsule_margin_loss: 0.0137 - val_output_capsule_mean_absolute_error: 0.0613 - val_output_capsule_acc: 0.9889 - val_reshape_1_margin_loss: 1.2839 - val_reshape_1_mean_absolute_error: 0.0749 - val_reshape_1_acc: 0.8057\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 20, 20, 256)  20992       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 6, 6, 256)    5308672     conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "primary_capsule_reshape (Reshap (None, 1152, 8)      0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "primary_capsule_squash (Lambda) (None, 1152, 8)      0           primary_capsule_reshape[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "digit_capsule (CapsuleLayer)    (None, 10, 16)       1486080     primary_capsule_squash[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking_layer_1 (MaskingLayer)  (None, 16)           0           digit_capsule[0][0]              \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          8704        masking_layer_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1024)         525312      dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 784)          803600      dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output_capsule (LengthLayer)    (None, 10)           0           digit_capsule[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 28, 28, 1)    0           dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 8,153,360\n",
      "Trainable params: 8,141,840\n",
      "Non-trainable params: 11,520\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers, models, optimizers\n",
    "from keras.layers import Input, Conv2D, Dense\n",
    "from keras.layers import Reshape, Layer, Lambda\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from keras import initializers\n",
    "from keras.optimizers import Adam\n",
    "from keras.datasets import mnist\n",
    "from keras import backend as K\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def squash(output_vector, axis=-1):\n",
    "    norm = tf.reduce_sum(tf.square(output_vector), axis, keep_dims=True)\n",
    "    return output_vector * norm / ((1 + norm) * tf.sqrt(norm + 1.0e-10))\n",
    "\n",
    "class MaskingLayer(Layer):\n",
    "    def call(self, inputs, **kwargs):\n",
    "        input, mask = inputs\n",
    "        return K.batch_dot(input, mask, 1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        *_, output_shape = input_shape[0]\n",
    "        return (None, output_shape)\n",
    "def PrimaryCapsule(n_vector, n_channel, n_kernel_size, n_stride, padding='valid'):\n",
    "    def builder(inputs):\n",
    "        output = Conv2D(filters=n_vector * n_channel, kernel_size=n_kernel_size, strides=n_stride, padding=padding)(inputs)\n",
    "        output = Reshape( target_shape=[-1, n_vector], name='primary_capsule_reshape')(output)\n",
    "        return Lambda(squash, name='primary_capsule_squash')(output)\n",
    "    return builder\n",
    "class CapsuleLayer(Layer):\n",
    "    def __init__(self, n_capsule, n_vec, n_routing, **kwargs):\n",
    "        super(CapsuleLayer, self).__init__(**kwargs)\n",
    "        self.n_capsule = n_capsule\n",
    "        self.n_vector = n_vec\n",
    "        self.n_routing = n_routing\n",
    "        self.kernel_initializer = initializers.get('he_normal')\n",
    "        self.bias_initializer = initializers.get('zeros')\n",
    "\n",
    "    def build(self, input_shape): # input_shape is a 4D tensor\n",
    "        _, self.input_n_capsule, self.input_n_vector, *_ = input_shape\n",
    "        self.W = self.add_weight(shape=[self.input_n_capsule, self.n_capsule, self.input_n_vector, self.n_vector], initializer=self.kernel_initializer, name='W')\n",
    "        self.bias = self.add_weight(shape=[1, self.input_n_capsule, self.n_capsule, 1, 1], initializer=self.bias_initializer, name='bias', trainable=False)\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        input_expand = tf.expand_dims(tf.expand_dims(inputs, 2), 2)\n",
    "        input_tiled = tf.tile(input_expand, [1, 1, self.n_capsule, 1, 1])\n",
    "        input_hat = tf.scan(lambda ac, x: K.batch_dot(x, self.W, [3, 2]), elems=input_tiled, initializer=K.zeros( [self.input_n_capsule, self.n_capsule, 1, self.n_vector]))\n",
    "        for i in range(self.n_routing): # routing\n",
    "            c = tf.nn.softmax(self.bias, dim=2)\n",
    "            outputs = squash(tf.reduce_sum( c * input_hat, axis=1, keep_dims=True))\n",
    "            if i != self.n_routing - 1:\n",
    "                self.bias += tf.reduce_sum(input_hat * outputs, axis=-1, keep_dims=True)\n",
    "        return tf.reshape(outputs, [-1, self.n_capsule, self.n_vector])\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        # output current layer capsules\n",
    "        return (None, self.n_capsule, self.n_vector)\n",
    "class LengthLayer(Layer):\n",
    "    def call(self, inputs, **kwargs):\n",
    "        return tf.sqrt(tf.reduce_sum(tf.square(inputs), axis=-1, keep_dims=False))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        *output_shape, _ = input_shape\n",
    "        return tuple(output_shape)\n",
    "def margin_loss(y_ground_truth, y_prediction):\n",
    "    _m_plus = 0.9\n",
    "    _m_minus = 0.1\n",
    "    _lambda = 0.5\n",
    "    L = y_ground_truth * tf.square(tf.maximum(0., _m_plus - y_prediction)) + _lambda * ( 1 - y_ground_truth) * tf.square(tf.maximum(0., y_prediction - _m_minus))\n",
    "    return tf.reduce_mean(tf.reduce_sum(L, axis=1))\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "y_train = to_categorical(y_train.astype('float32'))\n",
    "y_test = to_categorical(y_test.astype('float32'))\n",
    "X = np.concatenate((x_train, x_test), axis=0)\n",
    "Y = np.concatenate((y_train, y_test), axis=0)\n",
    "\n",
    "input_shape = [28, 28, 1]\n",
    "n_class = 10\n",
    "n_routing = 5\n",
    "\n",
    "x = Input(shape=input_shape)\n",
    "conv1 = Conv2D(filters=256, kernel_size=9, strides=1, padding='valid', activation='relu', name='conv1')(x)\n",
    "primary_capsule = PrimaryCapsule( n_vector=8, n_channel=32, n_kernel_size=9, n_stride=2)(conv1)\n",
    "digit_capsule = CapsuleLayer( n_capsule=n_class, n_vec=16, n_routing=n_routing, name='digit_capsule')(primary_capsule)\n",
    "output_capsule = LengthLayer(name='output_capsule')(digit_capsule)\n",
    "\n",
    "mask_input = Input(shape=(n_class, ))\n",
    "mask = MaskingLayer()([digit_capsule, mask_input])  # two inputs\n",
    "dec = Dense(512, activation='relu')(mask)\n",
    "dec = Dense(1024, activation='relu')(dec)\n",
    "dec = Dense(784, activation='sigmoid')(dec)\n",
    "dec = Reshape(input_shape)(dec)\n",
    "\n",
    "model = Model([x, mask_input], [output_capsule, dec])\n",
    "model.compile(optimizer='adam', loss=[ margin_loss, 'mae' ], metrics=[ margin_loss, 'mae', 'accuracy'])\n",
    "\n",
    "model.fit([X, Y], [Y, X], batch_size=128, epochs=3, validation_split=0.2)\n",
    "\n",
    "\n",
    "model.save('CapsNet_on_MNIST_with_4_routing.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
